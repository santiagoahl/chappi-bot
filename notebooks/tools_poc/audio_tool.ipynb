{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf9121e7",
   "metadata": {},
   "source": [
    "In this Notebook we create and sketch tools for the Agent. Building proofs of concept (PoC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29d8861",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d01490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09b59ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local Modules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32d7959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Whisper\n",
    "\n",
    "import whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e131840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Agent\n",
    "\n",
    "os.sys.path.append(\"../src\")\n",
    "os.sys.path.append(\"../src/agents\")\n",
    "\n",
    "import react  # My AI assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc02cd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG\n",
    "\n",
    "os.sys.path.append(\"../src/tools\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca7a88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import GAIA Questions\n",
    "from datasets import load_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46c1c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5cf241",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import snapshot_download, login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a3d4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Hugging face credentials\n",
    "\n",
    "#load_dotenv()\n",
    "#login(os.getenv(key=\"HF_TOKEN_CHAPPIE\"))  # Replace with your hf api key name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda05cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gaia_questions_path = snapshot_download(repo_id=\"gaia-benchmark/GAIA\", repo_type=\"dataset\")\n",
    "#gaia_questions = load_dataset(path=\"gaia-benchmark/GAIA\", name=\"2023_level1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ebf52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gaia_index_dir = \"../../../.cache/huggingface/datasets/gaia-benchmark___gaia/2023_level1/0.0.1/ec492fe4320ee795b1aed6bb46229c5f693226b0f1316347501c24b4baeee005\"\n",
    "#gaia_index_dir = os.path.abspath(gaia_index_dir)\n",
    "gaia_data_path = os.path.join(gaia_index_dir, \"gaia-validation.arrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101f8c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporal cell: wrote because of hugging face api calls limit\n",
    "\n",
    "import pyarrow.ipc as ipc\n",
    "\n",
    "with open(gaia_data_path, \"rb\") as f:\n",
    "    reader = ipc.RecordBatchStreamReader(f)\n",
    "    table = reader.read_all()\n",
    "\n",
    "gaia_df = table.to_pandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9a5e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gaia_questions = gaia_questions[\"validation\"]  # Filter for dev purposes\n",
    "#gaia_df = pd.DataFrame(gaia_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c08c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gaia_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4826e755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEL\n",
    "# temp filter to get chess images\n",
    "gaia_df[gaia_df[\"file_path\"].map(lambda f: f.endswith(\"44.png\"))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d34bca",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0150df47",
   "metadata": {},
   "outputs": [],
   "source": [
    "filetypes = {d[1].file_path.split(\".\")[-1] for d in gaia_df.iterrows()}\n",
    "filetypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9208da",
   "metadata": {},
   "source": [
    "### Read Historical XPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dd866a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xp_paths = \"../data/agent_experiments/iterations/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5649c3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index all XPs\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "xp_dir = \"../data/agent_experiments/iterations\"\n",
    "xp_list = []\n",
    "# FIXME: from the 10th XP iteration, the sorted method is unuseful\n",
    "\n",
    "for i, xp_path in enumerate(sorted(os.listdir(xp_paths))):  \n",
    "    xp_path = os.path.join(xp_dir, xp_path)\n",
    "    temp_xp_df = pd.read_csv(xp_path)\n",
    "    xp_list.append((i, temp_xp_df))\n",
    "    del temp_xp_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62498d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEL\n",
    "xp[xp[\"Question\"] == xp_question][[\"is_correct\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca5b1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join latest XP result to each question\n",
    "\n",
    "index = gaia_df.index.tolist()  # Index for all the questions\n",
    "questions = gaia_df[\"Question\"].tolist()\n",
    "answers = list()\n",
    "\n",
    "\n",
    "def filter_condition(xp_data: list) -> bool:\n",
    "    i, xp = xp_data\n",
    "    for question in questions:\n",
    "        xp_addressed_questions = xp[\"Question\"].tolist()\n",
    "        if question in xp_addressed_questions:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "filtered_xps = list(filter(filter_condition, xp_list))\n",
    "filtered_xps_reversed = filtered_xps\n",
    "filtered_xps_reversed.reverse()\n",
    "\n",
    "# Join latest answer result (i.e. result of the latest xp)\n",
    "\n",
    "# Join latest answer result (i.e. result of the latest xp)\n",
    "\n",
    "for question in questions:\n",
    "    answer_result = 0  # Assume wrong answer by default\n",
    "    for i, xp in filtered_xps_reversed:\n",
    "        for xp_question in xp[\"Question\"].tolist():\n",
    "            \n",
    "            if question == xp_question:\n",
    "                answer_result_row = list(xp[xp[\"Question\"] == xp_question][\"is_correct\"])#.loc[0]\n",
    "                answer_result_temp = answer_result_row[0]                    \n",
    "                if answer_result_temp >= answer_result:\n",
    "                    answer_result = answer_result_temp\n",
    "        del xp\n",
    "    answers.append(answer_result)\n",
    "\n",
    "# Join answers\n",
    "historical_xp_results = gaia_df.copy()\n",
    "historical_xp_results[\"is_correct\"] = pd.Series(answers)\n",
    "del answers, questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca756f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_xp_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd11615a",
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_xp_results.is_correct.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ddaede",
   "metadata": {},
   "source": [
    "Let's study first which are the most common wrong tasks. I.e. How can we increase accuracy with a single next step (e.g. implement a new tool, modify sys message, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0613fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_ans_df = historical_xp_results[historical_xp_results[\"is_correct\"]==0]\n",
    "wrong_ans_df[\"fp_extension\"] = wrong_ans_df[\"file_path\"].map(lambda path: path.split(\".\")[-1])\n",
    "wrong_ans_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43925ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "wrong_ans_df.groupby(\"fp_extension\")[\"is_correct\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f77dabb",
   "metadata": {},
   "source": [
    "The vast majority of remaining tasks do not include files to read. So we sould study them at first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1379da15",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_ans_df_no_extension = wrong_ans_df[wrong_ans_df[\"file_path\"].map(lambda fp: len(fp)==0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e40e190",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_ans_df_no_extension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cbc05d",
   "metadata": {},
   "source": [
    "## Audio Tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b579ef",
   "metadata": {},
   "source": [
    "Let's study where does our current Agent fail, especially on audio-like questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7a1444",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d3af35",
   "metadata": {},
   "outputs": [],
   "source": [
    "gaia_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9e932b",
   "metadata": {},
   "source": [
    "### Identify Audio-like tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8c9a12",
   "metadata": {},
   "source": [
    "The first questions is to understand which questions need audio? \n",
    "\n",
    "* Hypothesis: Just look at such questions that have a .mp3 file attached\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23516201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather a sample file from any task\n",
    "\n",
    "audio_tasks = gaia_df[(gaia_df[\"file_path\"].str.len()>0) & (gaia_df[\"file_path\"].str.endswith(\".mp3\"))]\n",
    "sample_task = audio_tasks.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa03a8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{(audio_tasks.shape[0] / gaia_df.shape[0]) * 100:.1f}% of tasks need audio processing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30a0394",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47c9bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the sample file\n",
    "\n",
    "filepath = sample_task[\"file_path\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d07cab8",
   "metadata": {},
   "source": [
    "Let's import the mp3 file with [ffmpeg](https://stackoverflow.com/questions/9458480/read-mp3-in-python-3#:~:text=%24%20ffmpeg%20%2Di%20foo.mp3%20%2Dvn%20%2Dacodec%20pcm_s16le%20%2Dac%201%20%2Dar%2044100%20%2Df%20wav%20foo.wav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82f6246",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_data_path = \"/home/santiagoal/current-projects/chappie/data/temp-data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e255c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if run:\n",
    "    os.system(f\"ffmpeg -i {filepath} -vn -acodec pcm_s16le -ac 1 -ar 44100 -f wav {temp_data_path}sample_audio.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9d0ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if run:\n",
    "    use_gpu = False\n",
    "    model_size = \"tiny\"\n",
    "\n",
    "    model = (\n",
    "        whisper.load_model(model_size).cuda()\n",
    "        if use_gpu\n",
    "        else whisper.load_model(model_size)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df808df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce2c352",
   "metadata": {},
   "outputs": [],
   "source": [
    "if run: \n",
    "    raw_transcript = model.transcribe(\n",
    "            filepath,\n",
    "            word_timestamps=False,\n",
    "            no_speech_threshold=0.5,\n",
    "            condition_on_previous_text=True,\n",
    "            compression_ratio_threshold=2.0,\n",
    "        )\n",
    "\n",
    "    transcript = raw_transcript[\"text\"]\n",
    "    print(transcript)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0654ee48",
   "metadata": {},
   "source": [
    "### Tool POC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83335239",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if run: \n",
    "    def transcriber(audio_path: str, ai_model = model) -> str:\n",
    "        \"\"\"\n",
    "        Transcribes an audio file\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        audio_path : str\n",
    "            Path to the audio file\n",
    "        ai_model\n",
    "            audio-to-text AI model \n",
    "\n",
    "        Returns:\n",
    "            str: Text of the transcript \n",
    "        \"\"\"\n",
    "        raw_transcript = ai_model.transcribe(\n",
    "            audio_path,\n",
    "            word_timestamps=False,\n",
    "            no_speech_threshold=0.5,\n",
    "            condition_on_previous_text=True,\n",
    "            compression_ratio_threshold=2.0,\n",
    "        )\n",
    "\n",
    "        transcript = raw_transcript[\"text\"]\n",
    "\n",
    "        return transcript"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9d4e58",
   "metadata": {},
   "source": [
    "### Integrate Tool POC and experiment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dee4276",
   "metadata": {},
   "source": [
    "The changes have been integrated, now we will experiment with the new version of the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811185e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_tasks[\"Agent response\"] = audio_tasks.apply(func=get_agent_response, axis=1)\n",
    "audio_tasks[\"is_correct\"] = audio_tasks.apply(func=eval_answer, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ab6ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e9241c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next steps: Update model... "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chappie-CHLGiFC_-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
