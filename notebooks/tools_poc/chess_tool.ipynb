{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf9121e7",
   "metadata": {},
   "source": [
    "In this Notebook we create and sketch tools for the Agent. Building proofs of concept (PoC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29d8861",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d01490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09b59ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local Modules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32d7959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Whisper\n",
    "\n",
    "import whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e131840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Agent\n",
    "\n",
    "os.sys.path.append(\"../src\")\n",
    "os.sys.path.append(\"../src/agents\")\n",
    "\n",
    "import react  # My AI assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc02cd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG\n",
    "\n",
    "os.sys.path.append(\"../src/tools\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca7a88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import GAIA Questions\n",
    "from datasets import load_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46c1c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5cf241",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import snapshot_download, login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a3d4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Hugging face credentials\n",
    "\n",
    "#load_dotenv()\n",
    "#login(os.getenv(key=\"HF_TOKEN_CHAPPIE\"))  # Replace with your hf api key name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda05cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gaia_questions_path = snapshot_download(repo_id=\"gaia-benchmark/GAIA\", repo_type=\"dataset\")\n",
    "#gaia_questions = load_dataset(path=\"gaia-benchmark/GAIA\", name=\"2023_level1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ebf52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gaia_index_dir = \"../../../.cache/huggingface/datasets/gaia-benchmark___gaia/2023_level1/0.0.1/ec492fe4320ee795b1aed6bb46229c5f693226b0f1316347501c24b4baeee005\"\n",
    "#gaia_index_dir = os.path.abspath(gaia_index_dir)\n",
    "gaia_data_path = os.path.join(gaia_index_dir, \"gaia-validation.arrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101f8c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporal cell: wrote because of hugging face api calls limit\n",
    "\n",
    "import pyarrow.ipc as ipc\n",
    "\n",
    "with open(gaia_data_path, \"rb\") as f:\n",
    "    reader = ipc.RecordBatchStreamReader(f)\n",
    "    table = reader.read_all()\n",
    "\n",
    "gaia_df = table.to_pandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9a5e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gaia_questions = gaia_questions[\"validation\"]  # Filter for dev purposes\n",
    "#gaia_df = pd.DataFrame(gaia_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c08c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gaia_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4826e755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEL\n",
    "# temp filter to get chess images\n",
    "gaia_df[gaia_df[\"file_path\"].map(lambda f: f.endswith(\"44.png\"))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d34bca",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0150df47",
   "metadata": {},
   "outputs": [],
   "source": [
    "filetypes = {d[1].file_path.split(\".\")[-1] for d in gaia_df.iterrows()}\n",
    "filetypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94422aae",
   "metadata": {},
   "source": [
    "### Read Historical XPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dd866a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xp_paths = \"../data/agent_experiments/iterations/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5649c3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index all XPs\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "xp_dir = \"../data/agent_experiments/iterations\"\n",
    "xp_list = []\n",
    "# FIXME: from the 10th XP iteration, the sorted method is unuseful\n",
    "\n",
    "for i, xp_path in enumerate(sorted(os.listdir(xp_paths))):  \n",
    "    xp_path = os.path.join(xp_dir, xp_path)\n",
    "    temp_xp_df = pd.read_csv(xp_path)\n",
    "    xp_list.append((i, temp_xp_df))\n",
    "    del temp_xp_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62498d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEL\n",
    "xp[xp[\"Question\"] == xp_question][[\"is_correct\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca5b1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join latest XP result to each question\n",
    "\n",
    "index = gaia_df.index.tolist()  # Index for all the questions\n",
    "questions = gaia_df[\"Question\"].tolist()\n",
    "answers = list()\n",
    "\n",
    "\n",
    "def filter_condition(xp_data: list) -> bool:\n",
    "    i, xp = xp_data\n",
    "    for question in questions:\n",
    "        xp_addressed_questions = xp[\"Question\"].tolist()\n",
    "        if question in xp_addressed_questions:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "filtered_xps = list(filter(filter_condition, xp_list))\n",
    "filtered_xps_reversed = filtered_xps\n",
    "filtered_xps_reversed.reverse()\n",
    "\n",
    "# Join latest answer result (i.e. result of the latest xp)\n",
    "\n",
    "# Join latest answer result (i.e. result of the latest xp)\n",
    "\n",
    "for question in questions:\n",
    "    answer_result = 0  # Assume wrong answer by default\n",
    "    for i, xp in filtered_xps_reversed:\n",
    "        for xp_question in xp[\"Question\"].tolist():\n",
    "            \n",
    "            if question == xp_question:\n",
    "                answer_result_row = list(xp[xp[\"Question\"] == xp_question][\"is_correct\"])#.loc[0]\n",
    "                answer_result_temp = answer_result_row[0]                    \n",
    "                if answer_result_temp >= answer_result:\n",
    "                    answer_result = answer_result_temp\n",
    "        del xp\n",
    "    answers.append(answer_result)\n",
    "\n",
    "# Join answers\n",
    "historical_xp_results = gaia_df.copy()\n",
    "historical_xp_results[\"is_correct\"] = pd.Series(answers)\n",
    "del answers, questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca756f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_xp_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd11615a",
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_xp_results.is_correct.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ddaede",
   "metadata": {},
   "source": [
    "Let's study first which are the most common wrong tasks. I.e. How can we increase accuracy with a single next step (e.g. implement a new tool, modify sys message, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0613fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_ans_df = historical_xp_results[historical_xp_results[\"is_correct\"]==0]\n",
    "wrong_ans_df[\"fp_extension\"] = wrong_ans_df[\"file_path\"].map(lambda path: path.split(\".\")[-1])\n",
    "wrong_ans_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43925ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "wrong_ans_df.groupby(\"fp_extension\")[\"is_correct\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f77dabb",
   "metadata": {},
   "source": [
    "The vast majority of remaining tasks do not include files to read. So we sould study them at first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1379da15",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_ans_df_no_extension = wrong_ans_df[wrong_ans_df[\"file_path\"].map(lambda fp: len(fp)==0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e40e190",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_ans_df_no_extension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4ce0bc",
   "metadata": {},
   "source": [
    "### Identify Image-like tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387e0aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_filetypes = ('png', 'jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec59bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_tasks_df = gaia_df[gaia_df[\"file_path\"].apply(lambda row: row.split(\".\")[-1] in img_filetypes)]\n",
    "image_tasks_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180294ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_tasks_df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d48c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "chess_task = image_tasks_df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d7605e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.isfile(chess_task.file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672fec32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image_path = chess_task.file_path\n",
    "image_bgr = cv2.imread(image_path)\n",
    "\n",
    "image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.imshow(image_rgb)\n",
    "plt.title(\"Chess Image\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d60868",
   "metadata": {},
   "source": [
    "### Chess Tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0738cd7",
   "metadata": {},
   "source": [
    "In this section, our methodology is to \n",
    "\n",
    "1. Use a CV model to get the FEN position of a 2D chess image\n",
    "2. Usea another model (likely stockfish) to predict the best move from a FEN position"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c16f891",
   "metadata": {},
   "source": [
    "#### Tool POC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d531e68",
   "metadata": {},
   "source": [
    "To extract the FEN position from the board image, we used [board_to_fen](https://github.com/mcdominik/board_to_fen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3a51d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cairosvg\n",
    "from io import BytesIO\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01860727",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from board_to_fen.predict import get_fen_from_image\n",
    "\n",
    "img = Image.open(chess_task.file_path)\n",
    "fen = get_fen_from_image(img, black_view=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e07228d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6819c048",
   "metadata": {},
   "source": [
    "We observed this position has no enough information about the current position, so we need to post process it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ba9e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "fen_cleaned = fen + \" b - - 0 1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac810f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fen_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f81960",
   "metadata": {},
   "source": [
    "Looking forward, we will need to a warn the AI agent to post-process the FEN before passing to stockfish. However, we can validate the prected FEN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6365917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try out with pychess\n",
    "\n",
    "import chess as c\n",
    "import chess.engine as ce\n",
    "\n",
    "board = c.Board(fen_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc3963d",
   "metadata": {},
   "outputs": [],
   "source": [
    "board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96037282",
   "metadata": {},
   "outputs": [],
   "source": [
    "svg_data = c.svg.board(board=board, flipped=True)\n",
    "png_data = BytesIO()\n",
    "cairosvg.svg2png(bytestring=svg_data.encode('utf-8'), write_to=png_data)\n",
    "png_data.seek(0)\n",
    "img_array = np.asarray(bytearray(png_data.read()), dtype=np.uint8)\n",
    "img = cv2.imdecode(img_array, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbe36a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(25, 10))\n",
    "\n",
    "ax[0].imshow(cv2.imread(chess_task.file_path))\n",
    "ax[0].axis(\"off\")\n",
    "ax[0].set_title(\"Original Chess Board\", fontsize=18)\n",
    "\n",
    "ax[1].imshow(img)\n",
    "ax[1].axis(\"off\")\n",
    "ax[1].set_title(f\"Predicted Chess Board\\nFEN: {fen_cleaned}\", fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1037165",
   "metadata": {},
   "source": [
    "Once we extracted the FEN chess position, we pass it to Stockfish in order to get the best next move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f340fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Stockfish \n",
    "stockfish_path = \"../external/chess-engines/stockfish/stockfish-ubuntu-x86-64-avx2\"\n",
    "chess_engine = ce.SimpleEngine.popen_uci(stockfish_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901f4ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict next best move \n",
    "stockfish_player = chess_engine.play(board=board, limit=ce.Limit(time=10))\n",
    "best_move_uci = stockfish_player.move\n",
    "best_move = board.san(move=best_move_uci) # Convert from Universal Chess interface to Standard Algebraic Notation\n",
    "best_move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2bffbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Results\\n\",\n",
    "    \"=\" * 30,\n",
    "    f\"\\nPredicted best next move: {best_move}\",\n",
    "    f\"\\nCorrect Answer: {chess_task['Final answer']}\"\n",
    "    f\"\\nIs the prediction correct?: {'yes' if best_move==chess_task['Final answer'] else 'no'}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d56f6c1",
   "metadata": {},
   "source": [
    "There we go! our model finds the correct answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb6d948",
   "metadata": {},
   "source": [
    "As a bonus, we might consider the case the board view is set from black or white pieces' perspective, so it worths considering to extract text from the board image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48f84bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "chess_img_path = \"/home/santiagoal/.cache/huggingface/hub/datasets--gaia-benchmark--GAIA/snapshots/897f2dfbb5c952b5c3c1509e648381f9c7b70316/2023/validation/cca530fc-4052-43b2-b130-b30968d8aa44.png\"\n",
    "cropped_chess_board_path = \"../data/images/cropped_chess_board.png\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df75df03",
   "metadata": {},
   "source": [
    "Our method is to crop the bottom-left chess square and extract the text. \n",
    "1. If the text is a1 -> The board has white view\n",
    "2. If the text is h8 -> The board has black view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e520a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Chess Board Img and Crop the bottom-left \n",
    "img_bgr = cv2.imread(chess_img_path)\n",
    "img_bgr = cv2.imread(chess_img_path)\n",
    "img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "img_np = np.array(img_rgb)\n",
    "img_np_shape = img_np.shape\n",
    "img_rows, img_cols = img_np_shape[:2]\n",
    "img_cropped = img_np[img_rows // 8 * 7:, :img_cols // 8 * 1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a332c910",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=2, nrows=1, figsize=(20, 10))\n",
    "\n",
    "ax[0].imshow(img_rgb)\n",
    "ax[1].imshow(img_cropped)\n",
    "\n",
    "ax[0].set_title(\"Original Image\")\n",
    "ax[1].set_title(\"Image Cropped\")\n",
    "\n",
    "ax[0].axis(\"off\")\n",
    "ax[1].axis(\"off\")\n",
    "\n",
    "fig.suptitle(\"Crop image to identify board orientation\", y=0.92, fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8723e6fd",
   "metadata": {},
   "source": [
    "Once we crop the board image, we might streamline a simple OCR model to extract the board text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60d5248",
   "metadata": {},
   "outputs": [],
   "source": [
    "import easyocr\n",
    "\n",
    "reader = easyocr.Reader(['en'], gpu=False)  \n",
    "\n",
    "results = reader.readtext(cropped_chess_board_path)\n",
    "results.reverse()\n",
    "\n",
    "# Grab text\n",
    "left_bottom_cell = \"\"\n",
    "for _, text_temp, _ in results:\n",
    "    left_bottom_cell += text_temp\n",
    "    \n",
    "print(f\"The left-bottom chess board square is {left_bottom_cell}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fadcf2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b579ef",
   "metadata": {},
   "source": [
    "Let's study where does our current Agent fail, especially on audio-like questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7a1444",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d3af35",
   "metadata": {},
   "outputs": [],
   "source": [
    "gaia_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chappie-CHLGiFC_-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
