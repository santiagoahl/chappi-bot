{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf9121e7",
   "metadata": {},
   "source": [
    "In this Notebook we create and sketch tools for the Agent. Building proofs of concept (PoC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29d8861",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d01490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09b59ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local Modules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32d7959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Whisper\n",
    "\n",
    "import whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e131840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Agent\n",
    "\n",
    "os.sys.path.append(\"../src\")\n",
    "os.sys.path.append(\"../src/agents\")\n",
    "\n",
    "import react  # My AI assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248cf6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.sys.path.append(\"../src/utils\")\n",
    "\n",
    "from gaia_eval import get_agent_response, evaluate_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca7a88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import GAIA Questions\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "gaia_questions = load_dataset(path=\"gaia-benchmark/GAIA\", name=\"2023_level1\")\n",
    "gaia_questions = gaia_questions[\"validation\"]  # Filter for dev purposes\n",
    "gaia_df = pd.DataFrame(gaia_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c08c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gaia_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d34bca",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0150df47",
   "metadata": {},
   "outputs": [],
   "source": [
    "filetypes = {d[1].file_path.split(\".\")[-1] for d in gaia_df.iterrows()}\n",
    "filetypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25a6fd5",
   "metadata": {},
   "source": [
    "## Image Handler Tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4ce0bc",
   "metadata": {},
   "source": [
    "### Identify Image-like tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387e0aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_filetypes = ('png', 'jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec59bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_tasks_df = gaia_df[gaia_df[\"file_path\"].apply(lambda row: row.split(\".\")[-1] in img_filetypes)]\n",
    "image_tasks_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180294ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_img_task = image_tasks_df.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c16f891",
   "metadata": {},
   "source": [
    "### Tool POC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1091615",
   "metadata": {},
   "source": [
    "#### (1/2) Donut for OCR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4bccd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Image\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "img_path = sample_img_task.file_path\n",
    "img = Image.open(img_path)\n",
    "task_description = sample_img_task.Question\n",
    "\n",
    "plt.title(\"Task: \" + task_description.replace(\".\", \".\\n\"))\n",
    "plt.imshow(img)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d0a8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies \n",
    "from DataProcessor\n",
    "from _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3b98e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup token processor and model\n",
    "\n",
    "processor = DataProcessor\n",
    "model = _(\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6926c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract info from image\n",
    "\n",
    "model.generate(\n",
    "    query\n",
    "    \n",
    "    ids=processor.tokenizer\n",
    "    tokens=512\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fb88cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show both image and result\n",
    "\n",
    ".batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b16f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "donut.model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873c65fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(donut.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ddc685",
   "metadata": {},
   "source": [
    "#### (2/2) YoLo for Object Detection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3467ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d6866d6d",
   "metadata": {},
   "source": [
    "### Integrate Tool and Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb541af5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "54fadcf2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cbc05d",
   "metadata": {},
   "source": [
    "## Audio Tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b579ef",
   "metadata": {},
   "source": [
    "Let's study where does our current Agent fail, especially on audio-like questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7a1444",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d3af35",
   "metadata": {},
   "outputs": [],
   "source": [
    "gaia_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9e932b",
   "metadata": {},
   "source": [
    "### Identify Audio-like tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8c9a12",
   "metadata": {},
   "source": [
    "The first questions is to understand which questions need audio? \n",
    "\n",
    "* Hypothesis: Just look at such questions that have a .mp3 file attached\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23516201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather a sample file from any task\n",
    "\n",
    "audio_tasks = gaia_df[(gaia_df[\"file_path\"].str.len()>0) & (gaia_df[\"file_path\"].str.endswith(\".mp3\"))]\n",
    "sample_task = audio_tasks.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa03a8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{(audio_tasks.shape[0] / gaia_df.shape[0]) * 100:.1f}% of tasks need audio processing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30a0394",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47c9bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the sample file\n",
    "\n",
    "filepath = sample_task[\"file_path\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d07cab8",
   "metadata": {},
   "source": [
    "Let's import the mp3 file with [ffmpeg](https://stackoverflow.com/questions/9458480/read-mp3-in-python-3#:~:text=%24%20ffmpeg%20%2Di%20foo.mp3%20%2Dvn%20%2Dacodec%20pcm_s16le%20%2Dac%201%20%2Dar%2044100%20%2Df%20wav%20foo.wav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82f6246",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_data_path = \"/home/santiagoal/current-projects/chappie/data/temp-data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e255c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if run:\n",
    "    os.system(f\"ffmpeg -i {filepath} -vn -acodec pcm_s16le -ac 1 -ar 44100 -f wav {temp_data_path}sample_audio.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9d0ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if run:\n",
    "    use_gpu = False\n",
    "    model_size = \"tiny\"\n",
    "\n",
    "    model = (\n",
    "        whisper.load_model(model_size).cuda()\n",
    "        if use_gpu\n",
    "        else whisper.load_model(model_size)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df808df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce2c352",
   "metadata": {},
   "outputs": [],
   "source": [
    "if run: \n",
    "    raw_transcript = model.transcribe(\n",
    "            filepath,\n",
    "            word_timestamps=False,\n",
    "            no_speech_threshold=0.5,\n",
    "            condition_on_previous_text=True,\n",
    "            compression_ratio_threshold=2.0,\n",
    "        )\n",
    "\n",
    "    transcript = raw_transcript[\"text\"]\n",
    "    print(transcript)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0654ee48",
   "metadata": {},
   "source": [
    "### Tool POC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83335239",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if run: \n",
    "    def transcriber(audio_path: str, ai_model = model) -> str:\n",
    "        \"\"\"\n",
    "        Transcribes an audio file\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        audio_path : str\n",
    "            Path to the audio file\n",
    "        ai_model\n",
    "            audio-to-text AI model \n",
    "\n",
    "        Returns:\n",
    "            str: Text of the transcript \n",
    "        \"\"\"\n",
    "        raw_transcript = ai_model.transcribe(\n",
    "            audio_path,\n",
    "            word_timestamps=False,\n",
    "            no_speech_threshold=0.5,\n",
    "            condition_on_previous_text=True,\n",
    "            compression_ratio_threshold=2.0,\n",
    "        )\n",
    "\n",
    "        transcript = raw_transcript[\"text\"]\n",
    "\n",
    "        return transcript"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9d4e58",
   "metadata": {},
   "source": [
    "### Integrate Tool POC and experiment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dee4276",
   "metadata": {},
   "source": [
    "The changes have been integrated, now we will experiment with the new version of the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811185e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_tasks[\"Agent response\"] = audio_tasks.apply(func=get_agent_response, axis=1)\n",
    "audio_tasks[\"is_correct\"] = audio_tasks.apply(func=eval_answer, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ab6ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e9241c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next steps: Update model... "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chappie-CHLGiFC_-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
